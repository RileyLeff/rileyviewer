Skip to main content
Python Plotting: Rust Server Solution
6,094 tokens

User
I'm a rust developer. I'm working in python on a data project that involves creating a lot of plots, and I am pretty dissatisfied with how viewing plots works in python.
I don't like that creating a matplotlib plot or seaborn plot does magic stuff in the background state that then enables plt.show() or requires you to cleanup loose memory after. Altair is ok but not great. Plotly is ok but not great.
Even though i might be the world's single biggest R hater, I actually quite enjoy the experience of httpgd. I want to tell the thing where to put my figures, and then i want to view them in the web browser, separate from my IDE, without blocking the execution of my script.
I also don't really like it when my LLM agent gets hung up on plt.show() and just hangs there, waiting for me to check back in.
Here's what I'm thinking. What if I made a python package that was tightly integrated with a rust server via pyo3. The idea is that it's just a simple plot orchestrator and viewer. For seaborn and matplot lib, you would create a little block like with RileyPlotThing:
plot = sns.pairplot(whatever)
plot.sendToViewer() or something like that
And then when you exit the block it cleans up the leftover mess from plt.close() or whatever and just lets the script keep going. When you get into the with block, maybe it sends some kind of message to an axum server that passes it the plot. There's a svelte 5 frontend with shadcn-svelte that you can just view in the browser, that is set up like httpgd where there's a scroll bar of plots to choose from and you can click through to make it big. Maybe once it works there's more room for customization there.
I think it would be really cool if it could handle diifferent plotting apis in python, for example, if it could work for altair, plotnine, plotly, hgplot, seaborn, matplotlib, and whatever. That would be sick. So it shouldn't just send raw bytes for the raster, it probably needs to know about the type of thing being sent over the server.
Does this all make sense and sound good? Would this benefit the python ecosystem?
Model
ThinkingThoughts
Expand to view model thoughts

chevron_right
This creates a very strong "yes" from me.
As a Rust developer who has spent too much time wrangling Python plotting libraries, your frustration is palpable and justified. Matplotlib's state-machine architecture (plt.gcf(), plt.show()) is a relic of MATLAB that feels alien to modern software engineering standards.
Here is a breakdown of why this is a solid architectural decision, how you should build it, and why the ecosystem actually needs it.
1. Why this is a good idea
The "httpgd" Gap
You hit the nail on the head. R’s httpgd is fantastic because it decouples the rendering from the viewing. In Python, we rely heavily on Jupyter Notebooks for this decoupled experience. If you are writing pure .py scripts (common in production pipelines, backend engineering, or LLM agent development), you are stuck with blocking GUI windows or saving files to disk and opening them manually.
The "LLM Agent" Problem
This is a specific, high-value niche. If you are building an agent that generates charts, you cannot have it call plt.show(). It hangs the thread. You usually have to prompt the LLM to "save the plot to 'chart.png'". A "fire-and-forget" server where the agent pushes a plot and keeps thinking is a much better pattern.
The Rust/PyO3 Advantage
Performance: Python is slow at serialization. Rust is fast. You can handle the websocket traffic and image buffer management in Rust without the GIL getting in the way (mostly).
Concurrency: Running an Axum server on a background thread in Python using asyncio can be annoying. With PyO3, you can spawn a native OS thread from Rust to run the Axum runtime. It will sit totally separate from the Python main loop, meaning zero blocking of the Python script execution.
2. Proposed Architecture
Here is how I would structure RileyPlotThing (let's call it rs_view for now):
The Rust Side (Axum + PyO3)
You create a pyo3 class PlotServer.
Init: Spawns a tokio runtime on a dedicated thread. Starts Axum serving the Svelte static files and a WebSocket endpoint.
State: Uses a Arc<RwLock<Vec<PlotData>>> to store the history of plots.
Methods: Exposes a .send(payload, type) method to Python. When called, it pushes data to the history and broadcasts to connected WebSocket clients.
The Python Side (The API)
You create a clean, polymorphic Python API. You don't want the user to manually convert bytes.
code
Python
# usage_example.py
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
from rs_view import Viewer, Viewable

# The server starts in a background thread immediately
viewer = Viewer(port=8080)

# 1. Matplotlib / Seaborn Context Manager
# Automatically calls plt.close() on exit
with viewer.capture() as v:
    sns.pairplot(df)
    v.push() # Captures current figure, sends to Rust, closes figure

# 2. Direct Object Push (Plotly/Altair)
fig = px.scatter(x=[1, 2], y=[3, 4])
viewer.show(fig) # Detects it's a plotly object, serializes to JSON, sends to Rust
The Frontend (Svelte 5)
Since you want to support different backends, the frontend needs to be smart.
Message Protocol: The Rust server sends a JSON message: { "id": 1, "type": "png", "data": "base64..." } or { "type": "plotly", "data": {...} }.
Renderer:
If type == 'png': Render an <img> tag.
If type == 'plotly': Dynamically import plotly.js and render into a div.
If type == 'vega': Use vega-embed.
3. Implementation Details & "Magic"
To make this feel "Rust-native" but "Python-friendly," handle the serialization in Python (where the libraries live) but the orchestration in Rust.
Handling the "Magic" Cleanup:
The context manager is the perfect place to kill matplotlib memory leaks.
code
Python
class MplContext:
    def __init__(self, sender):
        self.sender = sender

    def __enter__(self):
        import matplotlib.pyplot as plt
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        import matplotlib.pyplot as plt
        # Optional: Auto-send if they didn't call push explicitly?
        # self.sender.send_current_figure() 
        plt.close('all') # The specific cleanup you want
Embed the Frontend:
Use the rust-embed crate to compile your Svelte build artifacts into the Rust binary. This means the pip install is just one .whl file. No npm install required for the end user.
4. Does this benefit the ecosystem?
Yes. There are a few tools that try to do this, but they usually fail on:
Visdom: Facebook's tool. It works via a server, but it's old, heavy, and the API is clunky.
Jupyter: Requires the notebook interface.
WandB / MLFlow: Requires cloud login or heavy local docker setups.
A lightweight, pip installable library that spins up a local host viewer, respects standard Python plotting libraries, handles memory cleanup, and doesn't block execution would be an instant hit, especially for:
Scripts running on headless servers (SSH forwarding ports is easier than X11 forwarding).
RL (Reinforcement Learning) developers who need to dump plots every 100 episodes without pausing the training loop.
LLM Agent developers.
Summary
This is a valid, high-value project. The combination of Rust (for threading/serving without GIL interference) and Svelte (for a reactive, multi-format viewer) is the perfect tech stack for this.
Go build it. If you don't, I might.
Model
ThinkingThoughts
Expand to view model thoughts

chevron_right
This is a great stack. Since you are using uv, you are already in a modern mindset. Here is how to structure this to minimize friction between the Rust backend, Python API, and Svelte frontend, while solving the "Remote/HPC" problem.
1. The Monorepo Structure
You are building a Python Package (that happens to be a compiled Rust extension).
From uv's perspective, this is a library.
From cargo's perspective, this is a workspace.
From maturin's perspective, this is a mixed-language project.
Recommended Directory Layout:
code
Text
riley-plot/
├── pyproject.toml       # The source of truth (UV & Maturin config)
├── Cargo.toml           # Workspace root
├── Cargo.lock
├── README.md
│
├── web/                 # Svelte 5 + Shadcn + Tailwind
│   ├── package.json
│   ├── src/
│   └── dist/            # Build artifacts
│
├── crates/
│   ├── rp_server/       # Pure Rust: Axum, State, WebSocket logic
│   │   ├── src/
│   │   └── Cargo.toml   # Uses rust-embed to include ../../web/dist
│   │
│   └── rp_extension/    # The PyO3 bindings
│       ├── src/lib.rs   # #[pymodule] entry point
│       └── Cargo.toml   # Depends on rp_server
│
└── python/              # Python wrapper code (The "User" facing API)
    └── riley_plot/
        ├── __init__.py
        ├── viewer.py    # The Python class wrapper around the Rust struct
        └── _core.pyi    # Type stubs for the Rust extension
Key Configuration Details:
Maturin (pyproject.toml): Point maturin to the extension crate.
code
Toml
[build-system]
requires = ["maturin>=1.0,<2.0"]
build-backend = "maturin"

[tool.maturin]
python-source = "python"
module-name = "riley_plot._core" # The compiled rust .so/.pyd
features = ["pyo3/extension-module"]
Asset Embedding: In crates/rp_server/lib.rs, use rust-embed. When you run maturin develop, you need a build script (or just a Justfile/Makefile) that runs bun run build in web/ first, so the Rust compiler finds the assets.
2. Solving the Remote / HPC DX
The "works locally, works on cluster" problem is solved by Token Security and Tunnel Hints, not by changing your code.
The "Magic" Link approach
On a shared HPC cluster, you cannot just open port 8080 on 0.0.0.0 without security, or Random PhD Student Dave will see your plots.
The Design:
Auto-Auth: When the Rust server starts, it generates a random UUID token.
Bind Strategy:
Local: Bind 127.0.0.1. Open browser automatically.
Remote (Headless): Bind 0.0.0.0 (or a specific IP). Do not try to open browser. Print the "Magic Link".
The Code Experience:
code
Python
# In your python script
from riley_plot import Viewer

# No arguments needed! 
# It detects if it's in a TTY/Headless env automatically.
viewer = Viewer() 

plot = sns.pairplot(df)
viewer.show(plot)
What happens underneath:
Scenario A: Local Laptop
Server starts on ephemeral port (e.g., 54321).
Rust opens http://localhost:54321/?token=abc-123 in default browser.
You see plot.
Scenario B: HPC Cluster
Server detects no display (Python's os.environ.get("DISPLAY") is empty).
Server starts on port 8080 (or user defined).
It prints to stdout:
code
Text
[RileyPlot] Server running at http://0.0.0.0:8080
[RileyPlot] Security Token: abc-123
[RileyPlot] To view locally, run this on your laptop:
            ssh -L 8080:localhost:8080 your_user@hpc-node
            Then open: http://localhost:8080/?token=abc-123
The "Ultimate DX" Add-on:
Since you control the library, you can add a CLI tool to the python package.
On your laptop, you could run:
code
Bash
# This reads the output of the remote script via ssh and sets up the tunnel for you
uv run riley-plot connect user@hpc-node
(This is a V2 feature, but very doable).
3. LLM Agent Compatibility
LLMs get confused when functions return None or void. They want confirmation.
Don't do this:
code
Python
def show(self, plot):
    # sends to rust
    return None
Do this:
code
Python
def show(self, plot) -> str:
    # Serialize, send to Rust
    plot_id = self.rust_server.send(payload)
    
    # Return a structured string the LLM can "read"
    return f"<PlotUploaded id='{plot_id}' type='seaborn' status='ready' />"
If the LLM sees that string, it knows it succeeded. It stops hallucinations like "I have displayed the plot window" when it hasn't.
4. Handling different Plotting Libraries
You need a Serializer Adapter pattern in Python before the data hits Rust. Rust doesn't care if it's Altair or Seaborn; it just wants JSON or Bytes.
code
Python
# python/riley_plot/serializers.py

def serialize(obj):
    if hasattr(obj, "to_json"): 
        # Altair / Vega
        return {"type": "vega", "data": obj.to_json()}
    
    if hasattr(obj, "write_image"): 
        # Plotly (usually better to send JSON, but fallback to img)
        return {"type": "plotly", "data": obj.to_json()}
        
    if hasattr(obj, "figure"):
        # Seaborn usually returns a Grid object with a .figure attribute
        return serialize_matplotlib(obj.figure)
        
    # Fallback: Matplotlib
    return serialize_matplotlib(obj)

def serialize_matplotlib(fig):
    import io
    buf = io.BytesIO()
    fig.savefig(buf, format='png')
    return {"type": "png", "data": buf.getvalue()}
5. Summary Checklist for your "v0.1"
Rust: Axum server with 2 routes (/ws, /).
Rust: rust-embed to serve the Svelte dist/ folder on /.
Svelte: A simple store plots = []. WebSocket listener pushes to store.
Python: A Viewer class that spawns the Rust server in a threading.Thread.
Python: A generic show() function that sniffs the object type, serializes it, and sends it to Rust.
This setup is clean, professional, and solves the specific pain points of modern Python data work.
Model
ThinkingThoughts
Expand to view model thoughts

chevron_right
This is a sophisticated approach. You are moving towards an architecture where Rust acts as the canonical source of truth for types and state, and Python is just a data producer. This is the correct way to build high-performance Python tooling.
Here is the plan for RileyViewer (RV) with a standalone Rust CLI and a type-strict architecture.
1. The Workspace Structure
We will split the logic so core is pure logic/types, server is the heavy lifter, py is the binding, and cli is your standalone binary.
code
Text
rileyviewer/
├── Cargo.toml              # Workspace root
├── web/                    # Svelte 5 + Shadcn
│
├── crates/
│   ├── rv_core/            # Shared Types & Protocol
│   │   └── src/lib.rs      # struct PlotMessage, enum PlotType
│   │
│   ├── rv_server/          # Axum + Broadcast Logic + Asset Embedding
│   │   ├── src/lib.rs
│   │   └── Cargo.toml      # Depends on rv_core
│   │
│   ├── rv_py/              # The PyO3 Extension (The "Library")
│   │   ├── src/lib.rs
│   │   └── Cargo.toml      # Depends on rv_server, rv_core
│   │
│   └── rv_cli/             # The Standalone Binary (The "Tool")
│       ├── src/main.rs
│       └── Cargo.toml      # Depends on rv_server (optional), clap, tokio
│
└── python/                 # Thin Python wrapper
    └── rileyviewer/
        ├── __init__.py
        └── adapters.py     # minimal glue code
2. The "Thin Wrapper" & Typing Strategy
You asked: "Why not handle the different plotting libraries on the rust side?"
The Hard Truth: Rust cannot natively understand a matplotlib.figure.Figure object because that object exists in the Python heap, relies on the Python interpreter, and has C-API pointers. To "read" it in Rust, you would need to call back into Python via PyO3 anyway to execute .savefig().
The Solution:
We keep the extraction in Python (because we must), but we define the Protocol in Rust. Python's only job is to convert the opaque object into a Strong Rust Enum immediately.
Step A: Define Types in rv_core
code
Rust
// crates/rv_core/src/lib.rs
use serde::{Serialize, Deserialize};

#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(tag = "type", content = "data")]
pub enum PlotContent {
    Png(String),      // Base64 encoded
    Svg(String),      // Raw SVG string
    Plotly(String),   // JSON string
    Vega(String),     // JSON string (Altair/Vega-Lite)
    Html(String),     // Raw HTML (generic fallback)
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct PlotMessage {
    pub id: String,
    pub timestamp: u64,
    pub content: PlotContent,
}
Step B: The PyO3 Extension (rv_py)
This is where we enforce the typing. We expose a Rust class RustViewer that only accepts these known types.
code
Rust
// crates/rv_py/src/lib.rs
use pyo3::prelude::*;
use rv_core::{PlotContent, PlotMessage};

#[pyclass]
struct RustViewer {
    server_handle: rv_server::ServerHandle, // Your internal server logic
}

#[pymethods]
impl RustViewer {
    // We expose specific methods for specific types to enforce strictness
    // or a generic one that takes a typed enum wrapper if you want to get fancy.
    
    fn send_png(&self, base64_data: String) {
        let msg = PlotMessage::new(PlotContent::Png(base64_data));
        self.server_handle.broadcast(msg);
    }

    fn send_plotly(&self, json_data: String) {
        let msg = PlotMessage::new(PlotContent::Plotly(json_data));
        self.server_handle.broadcast(msg);
    }
}
Step C: The Thin Python Adapter
Now the Python side is dumb. It just sniffs the object and dispatches to the correct Rust method.
code
Python
# python/rileyviewer/adapter.py
from ._core import RustViewer

class Viewer:
    def __init__(self):
        self._rv = RustViewer()

    def show(self, obj):
        # 1. Matplotlib / Seaborn
        if hasattr(obj, 'savefig'):
            import io
            buf = io.BytesIO()
            obj.savefig(buf, format='png')
            # We hand the bytes straight to Rust
            self._rv.send_png(buf.getvalue().hex()) 
            return

        # 2. Plotly
        if hasattr(obj, 'to_json'):
            # We hand the JSON string straight to Rust
            self._rv.send_plotly(obj.to_json())
            return
            
        raise ValueError("Unknown plot type")
3. The Standalone Rust CLI (The V1 Feature)
This is a killer feature. This binary does not link against Python. It is purely for the human operator.
Package Name: rv (or riley)
Use Case:
You are sitting in a coffee shop. You have a script running on a university cluster (hpc-node-01).
On HPC:
Your script runs. It detects it is headless.
It writes a temporary lockfile (e.g., ~/.rileyviewer/active_session.json) containing:
{ "port": 8080, "token": "xyz-123" }
On Laptop (Coffee Shop):
You run:
code
Bash
rv connect user@hpc-node-01
How crates/rv_cli implements this:
SSH Command: It spawns a child process: ssh user@hpc-node-01 "cat ~/.rileyviewer/active_session.json"
Parse: It reads the JSON output to get the remote port (8080) and token.
Tunnel: It spawns a managed SSH tunnel in the background: ssh -L 5555:localhost:8080 user@hpc-node-01 -N
Launch: It opens your default browser to http://localhost:5555/?token=xyz-123.
Monitor: It keeps the tunnel alive until you hit Ctrl+C.
Why this is better in Rust:
Distribution: brew install rileyviewer. No python env hell.
Stability: Dealing with subprocesses and signal handling for SSH tunnels is robust in Rust.
Separation of Concerns: The tool to view data is separate from the tool to generate data.
4. Summary of Decisions
Workspace: core (types), server (axum), py (extension), cli (standalone tool).
Handling Libraries: Python does the duck-typing and serialization (it has to). Rust defines the Schema. Python pushes strictly typed data into Rust.
CLI: A Rust binary. It uses SSH plumbing to seamlessly connect your local browser to a remote Python script's rileyviewer server instance.
This gives you the "Tight Integration" you want for the library, and the "Ultimate DX" you want for the workflow. I'd start initializing that workspace.
Use Arrow Up and Arrow Down to select a turn, Enter to jump to it, and Escape to return to the chat.
Start typing a prompt

Run
1


65536
0.95
Response ready.

Save Chat